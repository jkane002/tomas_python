{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson 5: Web Scraping Continued",
      "provenance": [],
      "collapsed_sections": [
        "4AmHQnAO6UP9",
        "sGIYpA2949ZK"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq6oR46pHrLH",
        "colab_type": "text"
      },
      "source": [
        "# Lesson 5: Web Scraping Continued \n",
        "---\n",
        "Intro: Continuation from last lesson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QanMmuiXOoLE",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmcOXGqbwDzM",
        "colab_type": "text"
      },
      "source": [
        "1. What is web scraping? How can we use it in daily life?\n",
        "2. What is the HTML tag for hyperlinks? unordered lists?\n",
        "3. Why do we need to use BeautifulSoup?\n",
        "4. Why do we need to use the requests module?\n",
        "5. In the empty code block below, instantiate an object of the BeautifulSoup class where the website is called docweb and we will use the html.parser.\n",
        "6. What is the purpose of find_all()? find()?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhHwUwU2_pEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = beautifulsoup(docweb, html.parser)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glCedjN-Gd6s",
        "colab_type": "text"
      },
      "source": [
        "# Concept 1: Wikipedia Scraping\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25oLA8_cHOH7",
        "colab_type": "text"
      },
      "source": [
        "1. Open [Lesson 4](https://colab.research.google.com/drive/1R3RuNcXE2AVaRk87Mm6s9FK6PNhsKhHq) in another tab and put them side by side. We will use Lesson 4 as the continuation lesson and this workspace as the coding section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY4sg2jnCA9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "4255f007-dc76-4163-8635-35b59b247d77"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "page = response.content\n",
        "\n",
        "soup = BeautifulSoup(page, 'html.parser')\n",
        "\n",
        "inTheNews = soup.find('div', id='mp-tfa')\n",
        "news = inTheNews.find_all('li')\n",
        "\n",
        "for x in news:\n",
        "  print(x.get_text())\n",
        "  links = x.find_all('a')\n",
        "  for y in links:\n",
        "    print(y['href'])\n",
        "  print('\\t')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tricholoma pardinum\n",
            "/wiki/Tricholoma_pardinum\n",
            "\t\n",
            "Payún Matrú\n",
            "/wiki/Pay%C3%BAn_Matr%C3%BA\n",
            "\t\n",
            "History of the British farthing\n",
            "/wiki/History_of_the_British_farthing\n",
            "\t\n",
            "Archive\n",
            "/wiki/Wikipedia:Today%27s_featured_article/July_2020\n",
            "\t\n",
            "By email\n",
            "https://lists.wikimedia.org/mailman/listinfo/daily-article-l\n",
            "\t\n",
            "More featured articles\n",
            "/wiki/Wikipedia:Featured_articles\n",
            "\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlNZBNhJDczg",
        "colab_type": "text"
      },
      "source": [
        "# Concept 2: Bonus\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6quDSlNDhPq",
        "colab_type": "text"
      },
      "source": [
        "Use this if there is still more time.\n",
        "1. Look at list of [HTML tags](https://www.w3schools.com/TAGS/default.ASP). Focus on \\<table>, \\<td>, \\<tr>\n",
        "2. Think of other websites to scrape.\n",
        "* https://en.wikipedia.org/wiki/List_of_Presidents_of_the_United_States\n",
        "Print out all names of POTUS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7uCzxxmGzqP",
        "colab_type": "text"
      },
      "source": [
        "# Summary:\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q590kDmhCbPM",
        "colab_type": "text"
      },
      "source": [
        "1. Name different HTML tags\n",
        "2. How would you describe the coding process of web scraping who is trying to learn it?\n",
        "3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AmHQnAO6UP9",
        "colab_type": "text"
      },
      "source": [
        "# Homework:\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pG9QCmQDR6t",
        "colab_type": "text"
      },
      "source": [
        "1. Similar to the web scraping diy you did before, ask the user to enter a website. Now find all links from that website.\n",
        "Example:\n",
        "```\n",
        "Enter a website to extract the URL's from: google.com\n",
        "```\n",
        "> Hint: Use input()\n",
        "\n",
        "The output is this:\n",
        "```\n",
        "http://www.google.com/imghp?hl=en&tab=wi\n",
        "http://maps.google.com/maps?hl=en&tab=wl\n",
        "https://play.google.com/?hl=en&tab=w8\n",
        "http://www.youtube.com/?gl=US&tab=w1\n",
        "http://news.google.com/nwshp?hl=en&tab=wn\n",
        "https://mail.google.com/mail/?tab=wm\n",
        "https://drive.google.com/?tab=wo\n",
        "https://www.google.com/intl/en/about/products?tab=wh\n",
        "http://www.google.com/history/optout?hl=en\n",
        "/preferences?hl=en\n",
        "https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=http://www.google.com/\n",
        "/advanced_search?hl=en&authuser=0\n",
        "/intl/en/ads/\n",
        "/services/\n",
        "/intl/en/about.html\n",
        "/intl/en/policies/privacy/\n",
        "/intl/en/policies/terms/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGIYpA2949ZK",
        "colab_type": "text"
      },
      "source": [
        "# Notes on homework:\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu20Ty6QAuEq",
        "colab_type": "text"
      },
      "source": [
        "I will check in on Thursday,  through email to check on your progress. Respond with any questions you might have. Otherwise, a simple “all good” is appropriate if you have no questions or comments. \n",
        "\n",
        "You will need to upload your coding homework assignments to GitHub.\n",
        "1. In gitbash, change directories to the homework directory: tomas_python/homework\n",
        "* TIP: use ‘cd’ to change directories\n",
        "* Use ‘cd ..’ to return to the previous directory\n",
        "* Use ‘pwd’ to show full pathname of the current working directory \n",
        "* Use ‘ls’ to list all your directories\n",
        "2. Once you’re in that directory, type in ‘git pull’\n",
        "* This ensures you have all updated files\n",
        "* If there is an error involved, email me immediately so we can try resolving it.\n",
        "* Otherwise, type your code below and we’ll resolve issues next class\n",
        "3. To create a new file, type in ‘touch hw01.py’ or the appropriate file name\n",
        "* ‘Touch’ creates a new file\n",
        "4. Open up the python file and start coding!\n",
        "\n",
        "Note: Become familiar with these actions. This is essentially what happens in the backend when you right-click and create a new folder/file!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddKcgLGshg1S",
        "colab_type": "text"
      },
      "source": [
        "# DIY Solutions\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRSIvIhdhjzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_Presidents_of_the_United_States\"\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "tb = soup.find('table', class_='wikitable')\n",
        "\n",
        "for link in tb.find_all('b'):\n",
        "    name = link.find('a')\n",
        "    print(name.get_text('title'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}